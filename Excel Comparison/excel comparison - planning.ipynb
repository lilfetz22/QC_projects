{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path1 = f\"{planning_tool_proj_folder_location}/Todays Planning Tool Data - new env.xlsm\"\n",
    "file_path2 = f\"{planning_tool_proj_folder_location}/Todays Planning Tool Data.xlsm\"\n",
    "new_env_df = pd.read_excel(file_path1, sheet_name=\"HeatMap Base\")\n",
    "old_env_df = pd.read_excel(file_path2, sheet_name=\"HeatMap Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Column names below are arbitrary placeholders to demonstrate data cleaning process\n",
    "# while maintaining privacy of actual business data\n",
    "\n",
    "# drop columns that are not needed for comparison\n",
    "old_env_cols_dropped = ['Project Launch Date', 'Project Restart Date', 'Completion Date', 'System Access Required',\n",
    "                      'Priority Category', 'Priority Level', 'Task Reference ID']\n",
    "new_env_cols_dropped = ['Assignee: Full Name', 'Task Assignment ID']\n",
    "\n",
    "# columns to be renamed for consistency between old and new systems\n",
    "old_env_cols_renamed = ['Project: System ID', 'Project: Business Category', 'Project: Team Name', 'Project: Team Lead Name',\n",
    "                      'Project: Department Head', 'Project: Implementation Phase', 'System Access Grant Date']\n",
    "\n",
    "# new names for the columns being renamed\n",
    "old_env_cols_renamed_to = ['System ID', 'Business Category', 'Team Name', 'Team Lead: Full Name',\n",
    "                         'Department Head (DH)', 'Phase', 'System Access Granted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are not needed for comparison\n",
    "old_env_df_dropped = old_env_df.drop(old_env_cols_dropped, axis=1)\n",
    "new_env_df_dropped = new_env_df.drop(new_env_cols_dropped, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns are in old that are not in new\n",
    "old_env_cols = old_env_df_dropped.columns\n",
    "new_env_cols = new_env_df.columns\n",
    "old_env_cols_not_in_new = []\n",
    "for col in old_env_cols:\n",
    "    if col not in new_env_cols:\n",
    "        old_env_cols_not_in_new.append(col)\n",
    "print(old_env_cols_not_in_new)\n",
    "# reverse it\n",
    "new_env_cols_not_in_old = []\n",
    "for col in new_env_cols:\n",
    "    if col not in old_env_cols:\n",
    "        new_env_cols_not_in_old.append(col)\n",
    "print(new_env_cols_not_in_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "print(len(old_env_df_dropped.columns))\n",
    "print(len(new_env_df_dropped.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the old_env_df_dropped columns to match the new_env_df_dropped columns for only those that are in old_env_cols_renamed, and rename them to old_env_cols_renamed_to\n",
    "old_env_df_renamed = old_env_df_dropped.rename(columns=dict(zip(old_env_cols_renamed, old_env_cols_renamed_to)))\n",
    "old_env_df_renamed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_env_df_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the columns in both dataframes that have null values\n",
    "\n",
    "old_env_df_renamed['ID'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the max and min of every column in both dataframes\n",
    "print(\"old env max and min\")\n",
    "for col in old_env_df_renamed.columns:\n",
    "    if old_env_df_renamed[col].isnull().sum() > 0:\n",
    "        print(col)\n",
    "        try:\n",
    "            print(old_env_df_renamed[col].max())\n",
    "            print(old_env_df_renamed[col].min())\n",
    "        except:\n",
    "            # convert the column to a string\n",
    "            old_env_df_renamed[col] = old_env_df_renamed[col].astype(str)\n",
    "            print(old_env_df_renamed[col].max())\n",
    "            print(old_env_df_renamed[col].min())\n",
    "        print(\"\")\n",
    "print(\"new env max and min\")\n",
    "for col in new_env_df_dropped.columns:\n",
    "    if new_env_df_dropped[col].isnull().sum() > 0:\n",
    "        print(col)\n",
    "        try:\n",
    "            print(new_env_df_dropped[col].max())\n",
    "            print(new_env_df_dropped[col].min())\n",
    "        except:\n",
    "            # convert the column to a string\n",
    "            new_env_df_dropped[col] = new_env_df_dropped[col].astype(str)\n",
    "            print(new_env_df_dropped[col].max())\n",
    "            print(new_env_df_dropped[col].min())\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all null values in old_env_df_renamed with \"This was already Null\"\n",
    "old_env_df_na_filled = old_env_df_renamed.fillna(\"This was already Null\")\n",
    "# replace all null values in new_env_df_dropped with \"This was already Null\"\n",
    "new_env_df_na_filled = new_env_df_dropped.fillna(\"This was already Null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(new_env_df_na_filled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194642"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old_env_df_na_filled['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the old_env_df_dropped dataframe to new_env_df_dropped on ['Request: Request Id' = 'Source ID: Request Id'\n",
    "env_joined = pd.merge(old_env_df_na_filled, new_env_df_na_filled, on=cols, how='outer')\n",
    "env_joined_dups_dropped = env_joined.drop_duplicates()\n",
    "env_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in env_joined.columns:\n",
    "    if env_joined[col].isnull().sum() > 0:\n",
    "        print(col)\n",
    "        print(env_joined[col].isnull().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
