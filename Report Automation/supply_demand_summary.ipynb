{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply & Demand Analysis System\n",
    "## Business Intelligence Tool for Workforce Capacity Management\n",
    "\n",
    "\\* ***all business specific information has been removed or replaced with generic examples*** *\n",
    "\n",
    "### Overview\n",
    "This Jupyter notebook implements an automated system for analyzing and reporting on workforce supply and demand across different business categories. The system helps management make informed decisions about resource allocation, hiring needs, and capacity planning by comparing available workforce capacity against current business demands.\n",
    "\n",
    "### Business Context\n",
    "The system tracks two key metrics:\n",
    "- **Supply**: Available workforce capacity, including:\n",
    "  - Current workers with additional capacity\n",
    "  - New hires in training\n",
    "  - Workers completing certification programs\n",
    "  - Part-time and full-time staff availability\n",
    "- **Demand**: Business needs, including:\n",
    "  - Backfill requests for existing positions\n",
    "  - New project staffing requirements\n",
    "  - Additional capacity needs across different business categories\n",
    "\n",
    "### Technical Implementation\n",
    "This notebook:\n",
    "1. **Data Collection**:\n",
    "   - Pulls workforce data from Salesforce using custom queries\n",
    "   - Imports capacity base data from Excel files\n",
    "   - Retrieves historical supply/demand data for trend analysis\n",
    "\n",
    "2. **Data Processing**:\n",
    "   - Cleans and standardizes data from multiple sources\n",
    "   - Calculates key metrics like FTE (Full-Time Equivalent) capacity\n",
    "   - Segments data by business categories and worker types\n",
    "   - Handles various employment statuses (full-time, part-time, training)\n",
    "\n",
    "3. **Analysis**:\n",
    "   - Compares current supply against demand\n",
    "   - Calculates surpluses and deficits by category\n",
    "   - Tracks changes from previous weeks\n",
    "   - Identifies new capacity additions and filled positions\n",
    "\n",
    "4. **Reporting**:\n",
    "   - Generates a comprehensive Excel workbook with multiple sheets:\n",
    "     - Summary of current supply and demand\n",
    "     - Core business line analysis\n",
    "     - Week-over-week changes\n",
    "     - Detailed capacity changes\n",
    "     - Demand fluctuations\n",
    "\n",
    "### Output\n",
    "The final report provides stakeholders with:\n",
    "- Current state of workforce capacity\n",
    "- Areas requiring additional resources\n",
    "- Historical trends and changes\n",
    "- Detailed breakdowns by business category\n",
    "- Training pipeline visibility\n",
    "\n",
    "This automated system replaces manual tracking processes, providing consistent, accurate, and timely workforce capacity insights for strategic decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "from simple_salesforce import Salesforce\n",
    "# Import the module under a specific name\n",
    "import importlib\n",
    "import sf_queries_class\n",
    "importlib.reload(sf_queries_class)\n",
    "from sf_queries_class import SfQueries\n",
    "import my_sf_secrets\n",
    "import capacity_portion\n",
    "importlib.reload(capacity_portion)\n",
    "import create_capbase\n",
    "importlib.reload(create_capbase)\n",
    "my_sf_username, my_sf_password, my_sf_security_token = my_sf_secrets.get_my_sf_secrets()\n",
    "queries = SfQueries(\n",
    "    username=my_sf_username,\n",
    "    password=my_sf_password,\n",
    "    security_token=my_sf_security_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the username from the system\n",
    "username = os.getlogin()\n",
    "\n",
    "today = datetime.today().strftime('%B %d %Y').replace(\" 0\", \" \")\n",
    "filename = f\"{path_to_planning_teams_folder}CapBase/capbase {today}.xlsx\"\n",
    "print(f'{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(f\"{path_to_planning_teams_folder}/Supply Demand Summary/supply_demand_analysis_*.xlsx\")\n",
    "if all_files:\n",
    "    last_weeks_supply_demand = max(all_files, key=os.path.getctime)\n",
    "    \n",
    "    # Extract the date from the latest_file_path\n",
    "    latest_date_str = last_weeks_supply_demand.split('_')[-1].split('.')[0]\n",
    "    \n",
    "    # Convert the extracted date to datetime object for comparison\n",
    "    latest_date = datetime.strptime(latest_date_str, '%B %d %Y')\n",
    "    \n",
    "    # Compare with today's date\n",
    "    if latest_date.strftime('%B %d %Y') == today:\n",
    "        # Exclude the latest file and take the second newest\n",
    "        all_files.remove(last_weeks_supply_demand)\n",
    "        last_weeks_supply_demand = max(all_files, key=os.path.getctime)\n",
    "    \n",
    "    print(last_weeks_supply_demand)\n",
    "else:\n",
    "    print(\"No files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ops_data_pull_cleaned.sql', 'r') as file:\n",
    "    sql_query = file.read()\n",
    "# Now you can use cleaned_sql_query in your function\n",
    "\n",
    "sql_query_cleaned = sql_query.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_plan = queries.convert_salesforce_data_to_df(queries.sf.query_all(query=sql_query_cleaned))\n",
    "ops_plan = ops_plan.rename(columns={\n",
    "    'SF_COLUMN_NAME__c': 'RENAMED_COLUMN'\n",
    "})\n",
    "\n",
    "# Calculate 'RR_Age_Days'\n",
    "ops_plan['Created Date'] = pd.to_datetime(ops_plan['Created Date']) \n",
    "ops_plan['RR_Age_Days'] = (datetime.now().astimezone() - ops_plan['Created Date']).dt.days\n",
    "ops_plan['Requested FTE'] = round(ops_plan['Requested Hours'] / 40, 2)\n",
    "\n",
    "# Min-Max scaling for 'normalized_days'\n",
    "min_days = ops_plan['RR_Age_Days'].min()\n",
    "max_days = ops_plan['RR_Age_Days'].max() + 2\n",
    "ops_plan['normalized_days'] = (ops_plan['RR_Age_Days'] - min_days) / (max_days - min_days)\n",
    "\n",
    "# Calculate 'composite'\n",
    "ops_plan['composite'] = ops_plan['Staffing Request Priority Total'] + ops_plan['normalized_days']\n",
    "\n",
    "# Create 'In Implementation' column\n",
    "ops_plan['In Implementation'] = ops_plan['Stage'].apply(lambda x: 1 if x in ['In Implementation', 'Delayed'] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_plan_fil = ops_plan[((ops_plan['Status'] == 'Recruit') | (ops_plan['Status'] == 'Draft')) & \n",
    "                        ((ops_plan['Team Position'] != 'Backup Team Leader') & (ops_plan['Team Position'] != 'QAR')) & \n",
    "                        (ops_plan['Stage'] != 'Hold') & (ops_plan['Stage'] != 'Not Implemented')] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ops_plan_fil.columns:\n",
    "    if 'product' in col.lower():\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_plan_fil[(ops_plan_fil['Project Category'] == 'Cancer') & (ops_plan_fil['Team Position'] != 'CDSS')]['Primary Product Skilll: Case Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the Team Position is not CDSS but the product skill contains 'Follow up' or 'Case Finding' then the Team Position should be CDSS\n",
    "ops_plan_fil.loc[(ops_plan_fil['Project Category'] == 'Cancer') & (ops_plan_fil['Team Position'] != 'CDSS') &\n",
    "                    ((ops_plan_fil['Primary Product Skilll: Case Type'].str.contains('Follow up')) |\n",
    "                    (ops_plan_fil['Primary Product Skilll: Case Type'].str.contains('Case Finding'))), 'Team Position'] = 'CDSS'\n",
    "# replace 'Registry Operations' and 'Temporary Resource' with 'Abstractor'\n",
    "ops_plan_fil.loc[(ops_plan_fil['Project Category'] == 'Cancer') & ((ops_plan_fil['Team Position'] == 'Registry Operations') | \n",
    "                                                                   (ops_plan_fil['Team Position'] == 'Temporary Resource')), 'Team Position'] = 'Abstractor'\n",
    "# replace any 'Abstractor Depth' with 'Abstractor'\n",
    "ops_plan_fil.loc[((ops_plan_fil['Team Position'] == 'Abstractor Depth') |\n",
    "                  (ops_plan_fil['Team Position'] == 'Backup') |\n",
    "                  (ops_plan_fil['Team Position'] == 'Temporary Resource') |\n",
    "                  (ops_plan_fil['Team Position'] == 'Institute')), 'Team Position'] = 'Abstractor'\n",
    "\n",
    "ops_plan_gr = ops_plan_fil.groupby([\"Project Category\", \"Team Position\"]).sum(['Requested FTE', 'Requested Hours'])[['Requested FTE', 'Requested Hours']]\n",
    "ops_plan_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_plan_gr_index_reset = ops_plan_gr.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the excel file from the path\n",
    "try: \n",
    "    capbase = pd.read_excel(filename).fillna({'current_skills': \"\"})\n",
    "except:\n",
    "    create_capbase.create_capbase_file(queries)\n",
    "    capbase = pd.read_excel(filename).fillna({'current_skills': \"\"})\n",
    "capbase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_abstractors_only_1 = capbase[~(capbase['Resource Role'].isin(['Clinical Data Lead', \n",
    "                                                                      'Clinical Data Quality Specialist', \n",
    "                                                                      'Clinical Services Lead']))].copy()\n",
    "capbase_abstractors_only_1['Resource Role'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_abstractors_only_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grouping_fx(df, new_col, date_col):\n",
    "    # convert \n",
    "    df.loc[:, new_col] = (datetime.now() - pd.to_datetime(df[date_col])).dt.days\n",
    "    \n",
    "    choices = [\"negative\", \"<30\", \"30-89\", \"90-179\", \"180-364\", \">=YEAR\"]\n",
    "    \n",
    "    df.loc[:, f\"{new_col} Group\"] = pd.cut(df[new_col], \n",
    "                                 bins=[-float('inf'), -1, 29, 89, 179, 364, float('inf')],\n",
    "                                 labels=choices,\n",
    "                                 include_lowest=True)\n",
    "    \n",
    "    return df\n",
    "if 'Tenure Group' not in capbase_abstractors_only_1.columns:\n",
    "    capbase_abstractors_only_gr = grouping_fx(capbase_abstractors_only_1, 'Tenure', 'Resource_Start_Date')\n",
    "\n",
    "    capbase_Tr = capbase_abstractors_only_gr.copy()\n",
    "    capbase_Tr['Tr'] = capbase_Tr['Paid Onboarding Program'].isin([\n",
    "        \"Active - Institute\",\n",
    "        \"Active - Tr Oncology\",\n",
    "        \"Complete - Tr Oncology\",\n",
    "        \"Complete - Institute\"\n",
    "    ])\n",
    "\n",
    "    capbase_abstractors_only = capbase_Tr.copy()\n",
    "    capbase_abstractors_only['Tenure Group'] = np.select(\n",
    "        [\n",
    "            (capbase_abstractors_only['Tr'] & (capbase_abstractors_only['Tenure'] >= 0) & (capbase_abstractors_only['Tenure'] < 112)),\n",
    "            (capbase_abstractors_only['Tr'] & (capbase_abstractors_only['Tenure'] >= 112))\n",
    "        ],\n",
    "        [\n",
    "            \"Tr - Ramp\",\n",
    "            \"Tr - Mature\"\n",
    "        ],\n",
    "        default=capbase_abstractors_only['Tenure Group']\n",
    "    )\n",
    "else:\n",
    "    capbase_abstractors_only = capbase_abstractors_only_1.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_abstractors_only['Tenure Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_abstractors_only['Paid Onboarding Program'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_abstractors_only.loc[:, 'current_skills'] = np.where((capbase_abstractors_only['Group Name'] == 'GWTG') & \n",
    "                                                             (capbase_abstractors_only['Paid Onboarding Program'] == 'Active - Institute') &\n",
    "                                                              (capbase_abstractors_only['current_skills'].str.contains('Specific Category 1')),\n",
    "                                                              capbase_abstractors_only['current_skills'].str.replace('Specific Category 1', ''),\n",
    "                                                              capbase_abstractors_only['current_skills'])\n",
    "capbase_abstractors_only.loc[:, 'current_skills'] = np.where((capbase_abstractors_only['Group Name'] == 'Specific Category 1') & \n",
    "                                                             (capbase_abstractors_only['Paid Onboarding Program'] == 'Active - Institute') &\n",
    "                                                              (capbase_abstractors_only['current_skills'].str.contains('Specific Category 4')),\n",
    "                                                              capbase_abstractors_only['current_skills'].str.replace('Specific Category 4', ''),\n",
    "                                                              capbase_abstractors_only['current_skills'])\n",
    "# select CBIZ_Name, 'Full Time Status', 'Paid Onboarding Program', 'Tenure Group', 'current_skills', 'Capticket Hours', 'Capacity_Planned' from capbase\n",
    "capbase_sel = capbase_abstractors_only[['CBIZ_Name', 'Full Time Status', 'Paid Onboarding Program', \n",
    "                                        'Tenure Group', 'current_skills', 'Capticket Hours', 'Capacity_Planned', 'Senior Director', 'Group Name']]\n",
    "# drop duplicates\n",
    "capbase_sel = capbase_sel.drop_duplicates()\n",
    "# filter to only those individuals with Capticket Hours > 0 or Capacity_Planned > 0\n",
    "capbase_sel_capacity = capbase_sel[(capbase_sel['Capticket Hours'] > 0) | \n",
    "                          (~(capbase_sel['Paid Onboarding Program'].isin(['Active - Institute', 'Active - Oncology', 'Active - CDSS Oncology NTU'])) &\n",
    "                            (capbase_sel['Capacity_Planned'] > 0) & (capbase_sel['Tenure Group'].isin(['30-89', 'negative', '<30']))) |\n",
    "                            ((capbase_sel['Paid Onboarding Program'].isin(['Active - Institute', 'Active - Oncology', 'Active - CDSS Oncology NTU'])) &\n",
    "                            (capbase_sel['Capacity_Planned'] > 0))]\n",
    "# if 'current_skills' contains 'CM' but 'Senior Director' is not 'Paul Gasque', then replace 'CM' with ''\n",
    "capbase_sel_capacity.loc[:, 'current_skills'] = np.where(((capbase_sel_capacity['current_skills'].str.contains('Specific Category 1')) &\n",
    "                                                    (capbase_sel_capacity['Senior Director'] != 'SD NAME')) |\n",
    "                                                    ((capbase_sel_capacity['current_skills'].str.contains('Specific Category 1')) &\n",
    "                                                     ((capbase_sel_capacity['current_skills'].str.contains('Specific Category 2')) |\n",
    "                                                       (capbase_sel_capacity['current_skills'].str.contains('Specific Category 3')))), \n",
    "                                                       capbase_sel_capacity['current_skills'].str.replace('Specific Category 1', ''), \n",
    "                                                       capbase_sel_capacity['current_skills'])\n",
    "# if 'current_skills' is 'STS' then change it to 'STS-ACS'\n",
    "capbase_sel_capacity.loc[:, 'current_skills'] = np.where(capbase_sel_capacity['current_skills'].str.contains('Specific Category 4,'), capbase_sel_capacity['current_skills'].str.replace('Specific Category 4,', ''),\n",
    "                                                          capbase_sel_capacity['current_skills'])\n",
    "capbase_sel_capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_sel_capacity.loc[:, 'current_skills'] = capbase_sel_capacity['current_skills'].apply(lambda x: [item.strip() for item in str(x).split(',') if (item != ' ') & (item != '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for current_skills_length which is the length of the list in the current row of the 'current_skills' column\n",
    "capbase_sel_capacity.loc[:, 'current_skills_length'] = capbase_sel_capacity['current_skills'].apply(lambda x: len(x)).copy()\n",
    "# create a new column 'capacity' which is Capticket Hours unless it is null than fill it in with Capacity_Planned\n",
    "capbase_sel_capacity.loc[:, 'capacity'] = np.where(capbase_sel_capacity['Capticket Hours'].isnull(), (capbase_sel_capacity['Capacity_Planned'])/capbase_sel_capacity['current_skills_length'], \n",
    "                                                   (capbase_sel_capacity['Capticket Hours'])/capbase_sel_capacity['current_skills_length'])\n",
    "capbase_sel_capacity.loc[:, 'ticket_capacity'] = capbase_sel_capacity['Capticket Hours']/capbase_sel_capacity['current_skills_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode out the current_skills column for each of the lists in the current_skills column into multiple rows, one for each item in the list\n",
    "capbase_sel_capacity_exploded = capbase_sel_capacity.explode('current_skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_sel_capacity_exploded.groupby('current_skills').sum()[['capacity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill any 'Paid Onboarding Program' that is null with 'None'\n",
    "capbase_sel_capacity_exploded.loc[:, 'Paid Onboarding Program'] = capbase_sel_capacity_exploded['Paid Onboarding Program'].fillna('None')\n",
    "# if 'Paid Onboarding Program' contains 'Complete' then replace with 'Complete'\n",
    "capbase_sel_capacity_exploded.loc[:, 'Paid Onboarding Program'] = np.where(capbase_sel_capacity_exploded['Paid Onboarding Program'].str.contains('Complete'), 'Complete', capbase_sel_capacity_exploded['Paid Onboarding Program'])\n",
    "# if 'Paid Onboarding Program' is 'None' then replace with 'Complete'\n",
    "capbase_sel_capacity_exploded.loc[:, 'Paid Onboarding Program'] = np.where(capbase_sel_capacity_exploded['Paid Onboarding Program'] == 'None', 'Complete', capbase_sel_capacity_exploded['Paid Onboarding Program'])\n",
    "# if 'Paid Onboarding Program' contains 'Active' and 'Tr' then replace with 'Active - Institute'\n",
    "capbase_sel_capacity_exploded.loc[:, 'Paid Onboarding Program'] = np.where((capbase_sel_capacity_exploded['Paid Onboarding Program'].str.contains('Active')) &\n",
    "                                                                         (capbase_sel_capacity_exploded['Paid Onboarding Program'].str.contains('Tr')), 'Active - Institute', capbase_sel_capacity_exploded['Paid Onboarding Program'])\n",
    "# create a column called 'New Hires' which is if 'Tenure Group' is in ['30-89', 'negative', '<30']\n",
    "capbase_sel_capacity_exploded.loc[:, 'New Hires'] = np.where(capbase_sel_capacity_exploded['Tenure Group'].isin(['30-89', 'negative', '<30']), 'New Hires', '')\n",
    "capbase_sel_capacity_exploded.loc[:, 'Tr Hrs'] = np.where((capbase_sel_capacity_exploded['Tenure Group'] == 'Tr - Ramp') |\n",
    "                                                           ((capbase_sel_capacity_exploded['Tenure Group'].isin(['30-89', 'negative', '<30'])) & \n",
    "                                                             (capbase_sel_capacity_exploded['Paid Onboarding Program'] == 'Active - Institute')), 'Training', \n",
    "                                                           np.where((capbase_sel_capacity_exploded['Tenure Group'] == 'QCI - Mature') & \n",
    "                                                                    (capbase_sel_capacity_exploded['Paid Onboarding Program'] == 'Active - Institute'), 'Est', ''))\n",
    "\n",
    "capbase_sel_capacity_exploded_gr = capbase_sel_capacity_exploded.groupby(['current_skills', 'Full Time Status', 'Paid Onboarding Program', 'New Hires', 'Tr Hrs']).sum()[['capacity', 'Capticket Hours', 'ticket_capacity']].round(1)\n",
    "# add a column to capbase_sel_capacity_exploded_gr that is 'FTE capacity' which is 'capacity' divided by 40\n",
    "capbase_sel_capacity_exploded_gr.loc[:, 'FTE capacity'] = round(capbase_sel_capacity_exploded_gr['capacity']/40, 2)\n",
    "capbase_sel_capacity_exploded_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = pd.ExcelWriter(f\"{path_to_planning_teams_folder}/CapBase/supply_demand_raw_data_{today}.xlsx\", engine='xlsxwriter')\n",
    "# drop the 'Tenure_Group', 'Paid Onboarding Program' columns from capbase_sel_capacity_exploded\n",
    "capbase_sel_capacity_exploded_drp = capbase_sel_capacity_exploded.drop(['Tenure Group', 'Paid Onboarding Program'], axis = 1)\n",
    "capbase_sel_capacity_exploded_drp.loc[:, 'Run_Date'] = today\n",
    "# place Run_Date in the first column\n",
    "capbase_sel_capacity_exploded_drp = capbase_sel_capacity_exploded_drp[['Run_Date'] + list(capbase_sel_capacity_exploded_drp.columns[:-1])]\n",
    "capbase_sel_capacity_exploded_drp.to_excel(writer2, sheet_name = 'Supply', index = False)\n",
    "ops_plan_sel = ops_plan_fil.loc[:, ['Team Name', \"Project Category\", \"Team Position\",'Requested FTE', 'Requested Hours']]\n",
    "ops_plan_sel_gr0 = ops_plan_sel.loc[ops_plan_sel['Requested FTE'] > 0, :].copy()\n",
    "ops_plan_sel_gr0.loc[:, 'Run_Date'] = today\n",
    "ops_plan_sel_gr0 = ops_plan_sel_gr0.loc[:, ['Run_Date'] + list(ops_plan_sel_gr0.columns[:-1])]\n",
    "ops_plan_sel_gr0.to_excel(writer2, sheet_name = 'Demand', index = False)\n",
    "print(f\"{path_to_planning_teams_folder}/CapBase/supply_demand_raw_data_{today}.xlsx\")\n",
    "writer2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter ops_plan_gr_index_reset if Requested FTE > 0\n",
    "ops_plan_gr_index_reset_gr0 = ops_plan_gr_index_reset[ops_plan_gr_index_reset['Requested FTE'] > 0]\n",
    "# if the project Category == 'Cancer' then concatenate it with ' - ' and the 'Team Position'\n",
    "ops_plan_gr_index_reset_gr0.loc[:, 'Project Category'] = np.where(ops_plan_gr_index_reset_gr0['Project Category'] == 'Cancer', ops_plan_gr_index_reset_gr0['Project Category'] + ' - ' + ops_plan_gr_index_reset_gr0['Team Position'], ops_plan_gr_index_reset_gr0['Project Category'])\n",
    "ops_plan_gr_index_reset_gr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_sel_capacity_exploded_gr_index_reset = capbase_sel_capacity_exploded_gr.reset_index()\n",
    "capbase_sel_capacity_exploded_gr_index_reset.loc[:, 'current_skills'] = \\\n",
    "    np.where(((capbase_sel_capacity_exploded_gr_index_reset['current_skills'] == 'Cancer') & \n",
    "             (capbase_sel_capacity_exploded_gr_index_reset['Paid Onboarding Program'] == 'Active - Institute')), 'Cancer - CDSS', \n",
    "             np.where(((capbase_sel_capacity_exploded_gr_index_reset['current_skills'] == 'Cancer') & \n",
    "             ~(capbase_sel_capacity_exploded_gr_index_reset['Paid Onboarding Program'] == 'Active - Institute')), 'Cancer - Abstractor', capbase_sel_capacity_exploded_gr_index_reset['current_skills']))\n",
    "capbase_sel_capacity_exploded_gr_index_reset_gr = capbase_sel_capacity_exploded_gr_index_reset.groupby('current_skills').sum()[['FTE capacity']]\n",
    "capbase_sel_capacity_exploded_gr_index_reset_gr2 = capbase_sel_capacity_exploded_gr_index_reset_gr.reset_index()\n",
    "capbase_sel_capacity_exploded_gr_index_reset_gr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just what we need for supply demand analysis\n",
    "capbase_sel_capacity_exploded_gr_index_reset_gr = capbase_sel_capacity_exploded_gr_index_reset.groupby('current_skills').sum()[['FTE capacity']]\n",
    "capbase_sel_capacity_exploded_gr_index_reset_gr2 = capbase_sel_capacity_exploded_gr_index_reset_gr.reset_index()\n",
    "\n",
    "# only what we need from ops plan\n",
    "ops_plan_gr_index_reset_gr0_sel = ops_plan_gr_index_reset_gr0[['Project Category','Requested FTE']]\n",
    "\n",
    "supply_demand = capbase_sel_capacity_exploded_gr_index_reset_gr2.merge(ops_plan_gr_index_reset_gr0_sel, left_on='current_skills', right_on='Project Category', how='outer')\n",
    "# grab the first non-nan value from current_skills and Project Category and put them into current_skills\n",
    "supply_demand.loc[:, 'current_skills'] = supply_demand['current_skills'].fillna(supply_demand['Project Category'])\n",
    "# drop the project category column\n",
    "supply_demand = supply_demand.drop(columns=['Project Category'])\n",
    "# rename current_skills to 'Project Category'\n",
    "supply_demand = supply_demand.rename(columns={'current_skills': 'Product Category'})\n",
    "# replace the NaN's in Requested FTE with 0\n",
    "# supply_demand.loc[:, 'Requested FTE'] = supply_demand['Requested FTE'].fillna(0)\n",
    "# create a column for the difference between FTE capacity and Requested FTE if either are null then fill with 0 to get the surplus or deficit\n",
    "supply_demand.loc[:, 'FTE capacity_null_filled'] = supply_demand['FTE capacity'].fillna(0)\n",
    "supply_demand.loc[:, 'Requested FTE_null_filled'] = supply_demand['Requested FTE'].fillna(0)\n",
    "supply_demand.loc[:, 'Surplus/(Deficit)'] = supply_demand['FTE capacity_null_filled'] - supply_demand['Requested FTE_null_filled']\n",
    "# drop the columns that were used to calculate the surplus/deficit\n",
    "supply_demand = supply_demand.drop(columns=['FTE capacity_null_filled', 'Requested FTE_null_filled'])\n",
    "supply_demand = supply_demand.sort_values('Product Category')\n",
    "supply_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in capbase_sel_capacity_exploded_gr_index_reset create a new column that concatenates 'Full Time Status' and  'Paid Onboarding Program'  with a ' - '\n",
    "capbase_sel_capacity_exploded_gr_index_reset.loc[:, 'POB'] = capbase_sel_capacity_exploded_gr_index_reset['Full Time Status'] + ' - ' + capbase_sel_capacity_exploded_gr_index_reset['Paid Onboarding Program']\n",
    "capbase_sel_capacity_exploded_gr_index_reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supply Break Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_sel_capacity_exploded_gr_index_reset_cols_dropped = capbase_sel_capacity_exploded_gr_index_reset.drop(columns=['New Hires', 'Tr Hrs', 'Capticket Hours'])\n",
    "# drop duplicate rows\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_dropped = capbase_sel_capacity_exploded_gr_index_reset_cols_dropped.groupby(['current_skills', 'POB']).sum()[['FTE capacity']]\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_dropped_index_reset = capbase_sel_capacity_exploded_gr_index_reset_cols_dropped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe that has current_skills on the x-axis then creates a new column for each unique value in the 'POB' column and for the values uses the 'FTE capacity' column\n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot = capbase_sel_capacity_exploded_gr_index_reset_cols_dropped_index_reset.pivot(index='current_skills', columns='POB', values='FTE capacity')\n",
    "# if any of these columns are missing: FT - Active\tFT - Active - QC Institute\tFT - Complete\tPT - Complete then create a column of nans\n",
    "for col in ['FT - Active', 'FT - Active - Institute', 'FT - Complete', 'PT - Complete']:\n",
    "    if col not in capbase_sel_capacity_exploded_gr_index_reset_pivot.columns:\n",
    "        capbase_sel_capacity_exploded_gr_index_reset_pivot[col] = np.nan\n",
    "# capbase_sel_capacity_exploded_gr_index_reset_pivot = capbase_sel_capacity_exploded_gr_index_reset_pivot.fillna(0)\n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index supply_demand to 'Product Category'\n",
    "supply_demand_pr_index = supply_demand.set_index('Product Category')\n",
    "# merge the supply_demand_pr_index with capbase_sel_capacity_exploded_gr_index_reset_pivot on the index\n",
    "supply_demand_pr_index_merged = supply_demand_pr_index.merge(capbase_sel_capacity_exploded_gr_index_reset_pivot, left_index=True, right_index=True, how='left')\n",
    "supply_demand_pr_index_merged_fil = supply_demand_pr_index_merged.loc[['Cat 1', 'Cat 2', 'Cat3'], :]\n",
    "supply_demand_pr_index_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity Tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capbase_sel_capacity_exploded_gr_index_reset_cols_dropped = capbase_sel_capacity_exploded_gr_index_reset.drop(columns=['New Hires', 'QCI Hrs', 'Capticket Hours'])\n",
    "# drop duplicate rows\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_tickets = capbase_sel_capacity_exploded_gr_index_reset.groupby(['current_skills', 'POB']).sum()[['ticket_capacity']]\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_tickets_index_reset = capbase_sel_capacity_exploded_gr_index_reset_cols_tickets.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capbase_sel_capacity_exploded_gr_index_reset_pivot_tickets = capbase_sel_capacity_exploded_gr_index_reset_cols_tickets_index_reset.pivot(index='current_skills', columns='POB', values='ticket_capacity')\n",
    "# add '_tickets' to all the column names \n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot_tickets.columns = [col + '_tickets' for col in capbase_sel_capacity_exploded_gr_index_reset_pivot_tickets.columns]\n",
    "# if any of these columns are missing: FT - Active_tickets\tFT - Active - QC Institute_tickets\tFT - Complete_tickets\tPT - Complete_tickets then create a column of nans\n",
    "for col in ['FT - Active_tickets', 'FT - Active - QC Institute_tickets', 'FT - Complete_tickets', 'PT - Complete_tickets']:\n",
    "    if col not in capbase_sel_capacity_exploded_gr_index_reset_pivot_tickets.columns:\n",
    "        capbase_sel_capacity_exploded_gr_index_reset_pivot_tickets[col] = np.nan\n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot_tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the supply_demand_pr_index with capbase_sel_capacity_exploded_gr_index_reset_pivot on the index\n",
    "supply_demand_pr_index_merged_tickets = supply_demand_pr_index_merged.merge(capbase_sel_capacity_exploded_gr_index_reset_pivot_tickets, left_index=True, right_index=True, how='left')\n",
    "supply_demand_pr_index_merged_tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QCI Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter capbase_sel_capacity_exploded_gr_index_reset to where 'QCI Hrs' doesn't equal ''\n",
    "capbase_sel_capacity_exploded_gr_index_reset_QCI_hrs = capbase_sel_capacity_exploded_gr_index_reset[capbase_sel_capacity_exploded_gr_index_reset['QCI Hrs'] != '']\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_QCI_hrs = capbase_sel_capacity_exploded_gr_index_reset_QCI_hrs.groupby(['current_skills', 'QCI Hrs']).sum()[['capacity']]\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_QCI_hrs_index_reset = capbase_sel_capacity_exploded_gr_index_reset_cols_QCI_hrs.reset_index()\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_QCI_hrs_index_reset\n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs = capbase_sel_capacity_exploded_gr_index_reset_cols_QCI_hrs_index_reset.pivot(index='current_skills', columns='QCI Hrs', values='capacity')\n",
    "# # add '_QCI_hrs' to all the column names \n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs.columns = [col + '_QCI_hrs' for col in capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs.columns]\n",
    "# if Training_QCI_hrs doesn't exist, add a column of NaNs\n",
    "if 'Training_QCI_hrs' not in capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs.columns:\n",
    "    capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs['Training_QCI_hrs'] = np.nan\n",
    "if 'Est_QCI_hrs' not in capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs.columns:\n",
    "    capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs['Est_QCI_hrs'] = np.nan\n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_demand_pr_index_merged_QCI_hrs = supply_demand_pr_index_merged_tickets.merge(capbase_sel_capacity_exploded_gr_index_reset_pivot_QCI_hrs, left_index=True, right_index=True, how='left')\n",
    "supply_demand_pr_index_merged_QCI_hrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Hires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter capbase_sel_capacity_exploded_gr_index_reset to where 'QCI Hrs' doesn't equal ''\n",
    "capbase_sel_capacity_exploded_gr_index_reset_new_hires = capbase_sel_capacity_exploded_gr_index_reset.loc[capbase_sel_capacity_exploded_gr_index_reset['New Hires'] != '']\n",
    "capbase_sel_capacity_exploded_gr_index_reset_new_hires.loc[:, 'Status - New Hire'] = capbase_sel_capacity_exploded_gr_index_reset_new_hires['Full Time Status'] + ' - ' + capbase_sel_capacity_exploded_gr_index_reset_new_hires['New Hires']\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_new_hires = capbase_sel_capacity_exploded_gr_index_reset_new_hires.groupby(['current_skills', 'Status - New Hire']).sum()[['capacity']]\n",
    "capbase_sel_capacity_exploded_gr_index_reset_cols_new_hires_index_reset = capbase_sel_capacity_exploded_gr_index_reset_cols_new_hires.reset_index()\n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot_new_hires = capbase_sel_capacity_exploded_gr_index_reset_cols_new_hires_index_reset.pivot(index='current_skills', columns='Status - New Hire', values='capacity')\n",
    "if 'FT - New Hires' not in capbase_sel_capacity_exploded_gr_index_reset_pivot_new_hires.columns:\n",
    "    capbase_sel_capacity_exploded_gr_index_reset_pivot_new_hires['FT - New Hires'] = np.nan\n",
    "if 'PT - New Hires' not in capbase_sel_capacity_exploded_gr_index_reset_pivot_new_hires.columns:\n",
    "    capbase_sel_capacity_exploded_gr_index_reset_pivot_new_hires['PT - New Hires'] = np.nan\n",
    "capbase_sel_capacity_exploded_gr_index_reset_pivot_new_hires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_demand_pr_index_merged_new_hires = supply_demand_pr_index_merged_QCI_hrs.merge(capbase_sel_capacity_exploded_gr_index_reset_pivot_new_hires, left_index=True, right_index=True, how='left')\n",
    "supply_demand_pr_index_merged_new_hires_no_multi = supply_demand_pr_index_merged_new_hires.copy()\n",
    "supply_demand_pr_index_merged_new_hires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_demand_pr_index_merged_new_hires.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming supply_demand_pr_index_merged_new_hires is already defined and loaded\n",
    "\n",
    "# Define the labels for the primary column index\n",
    "primary_column_labels = ['Overall', 'Supply Breakdown', 'Tickets', 'Tr Hrs', 'New Hires']\n",
    "column_labels_full = []\n",
    "for label, num_cols in zip(primary_column_labels, [3, 4, 4, 2, 2]):\n",
    "    labels_i = [label] * num_cols\n",
    "    column_labels_full.extend(labels_i)\n",
    "\n",
    "# Create a MultiIndex for the columns\n",
    "multiindex = pd.MultiIndex.from_arrays([column_labels_full, supply_demand_pr_index_merged_new_hires.columns])\n",
    "\n",
    "# Assign the new MultiIndex to the DataFrame\n",
    "supply_demand_pr_index_merged_new_hires.columns = multiindex\n",
    "supply_demand_pr_index_merged_new_hires\n",
    "# Reset the index to make the primary column index part of the DataFrame's columns again\n",
    "# supply_demand_pr_index_merged_new_hires.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel\n",
    "# supply_demand_pr_index_merged_new_hires.to_excel(f\"{path_to_planning_teams_folder}supply_demand_analysis_{today}.xlsx\", index=True, sheet_name = 'Summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to last week's Supply Demand Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import last_weeks_supply_demand_summary and skip the first row and set the index to 'Unnamed: 0' \n",
    "last_weeks_supply_demand_summary = pd.read_excel(last_weeks_supply_demand, sheet_name='Summary', skiprows=1, index_col='Unnamed: 0')\n",
    "# remove the first row\n",
    "last_weeks_supply_demand_summary = last_weeks_supply_demand_summary.iloc[1:]\n",
    "# last_weeks_supply_demand_summary.columns = multiindex\n",
    "# fill all the nans with 0\n",
    "last_weeks_supply_demand_summary = last_weeks_supply_demand_summary.fillna(0)\n",
    "# add '_last_week' to all the columns\n",
    "last_weeks_supply_demand_summary.columns = [col + '_last_week' for col in last_weeks_supply_demand_summary.columns]\n",
    "last_weeks_supply_demand_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all the nans in supply_demand_pr_index_merged_new_hires with 0\n",
    "supply_demand_pr_index_merged_new_hires_no_multi = supply_demand_pr_index_merged_new_hires_no_multi.fillna(0)\n",
    "supply_demand_pr_index_merged_new_hires_no_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do an outer join of supply_demand_pr_index_merged_new_hires_no_multi and last_weeks_supply_demand_summary\n",
    "supply_demand_pr_index_merged_new_hires_no_multi_last_week = supply_demand_pr_index_merged_new_hires_no_multi.merge(last_weeks_supply_demand_summary, left_index=True, right_index=True, how='outer', suffixes=('', '_last_week'))\n",
    "\n",
    "# Create 'diff' columns only for columns that exist in both current and previous week\n",
    "for col in supply_demand_pr_index_merged_new_hires_no_multi.columns:\n",
    "    if f'{col}_last_week' in supply_demand_pr_index_merged_new_hires_no_multi_last_week.columns:\n",
    "        supply_demand_pr_index_merged_new_hires_no_multi_last_week[f'{col}_diff'] = supply_demand_pr_index_merged_new_hires_no_multi_last_week[col] - supply_demand_pr_index_merged_new_hires_no_multi_last_week[f'{col}_last_week']\n",
    "\n",
    "# Order the columns\n",
    "cols = []\n",
    "for col in supply_demand_pr_index_merged_new_hires_no_multi.columns:\n",
    "    cols.append(col)\n",
    "    if f'{col}_last_week' in supply_demand_pr_index_merged_new_hires_no_multi_last_week.columns:\n",
    "        cols.extend([f'{col}_last_week', f'{col}_diff'])\n",
    "\n",
    "supply_demand_pr_index_merged_new_hires_no_multi_last_week = supply_demand_pr_index_merged_new_hires_no_multi_last_week[cols]\n",
    "\n",
    "# Replace 0s with NaNs\n",
    "supply_demand_pr_index_merged_new_hires_no_multi_last_week = supply_demand_pr_index_merged_new_hires_no_multi_last_week.replace(0, np.nan)\n",
    "\n",
    "supply_demand_pr_index_merged_new_hires_no_multi_last_week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in the raw data from last week\n",
    "supply_last_week = pd.read_excel(f\"{path_to_planning_teams_folder}/CapBase/supply_demand_raw_data_{latest_date_str}.xlsx\", sheet_name='Supply')\n",
    "demand_last_week = pd.read_excel(f\"{path_to_planning_teams_folder}/CapBase/supply_demand_raw_data_{latest_date_str}.xlsx\", sheet_name='Demand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat supply_last_week to the bottom of capbase_sel_capacity_exploded_drp\n",
    "supply_raw_both_weeks = pd.concat([capbase_sel_capacity_exploded_drp, supply_last_week])\n",
    "# replace '' with np.nan\n",
    "supply_raw_both_weeks = supply_raw_both_weeks.replace('', np.nan)\n",
    "print(len(supply_raw_both_weeks))\n",
    "# replace any nans with 0\n",
    "supply_raw_both_weeks = supply_raw_both_weeks.fillna(0)\n",
    "# group by 'CBIZ_Name', 'Full Time Status', 'current_skills', 'Capticket Hours', 'capacity'\n",
    "supply_raw_both_weeks_gr = supply_raw_both_weeks.groupby(['CBIZ_Name', 'Full Time Status', 'current_skills', 'Capticket Hours', 'capacity']).count()['Run_Date'].reset_index()\n",
    "supply_raw_both_weeks_gr = supply_raw_both_weeks_gr.rename(columns={'Run_Date': 'count'})\n",
    "supply_raw_both_weeks_gr.loc[:, 'Changed'] = np.where(supply_raw_both_weeks_gr['count'] > 1, 'No', 'Yes')\n",
    "# drop count column\n",
    "supply_raw_both_weeks_gr = supply_raw_both_weeks_gr.drop(columns=['count'])\n",
    "# join this back to the supply_raw_both_weeks dataframe\n",
    "supply_raw_both_weeks_joined = supply_raw_both_weeks.merge(supply_raw_both_weeks_gr, on=['CBIZ_Name', 'Full Time Status', 'current_skills', 'Capticket Hours', 'capacity'], how='left')\n",
    "supply_raw_both_weeks_joined\n",
    "# supply_raw_both_weeks = supply_raw_both_weeks.drop_duplicates(subset=['CBIZ_Name', 'Full Time Status', 'current_skills', 'Capticket Hours', 'capacity'])\n",
    "# supply_raw_both_weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distinct values in the 'Run_Date' and 'CBIZ_Name' columns\n",
    "dups_dropped_cbiz = supply_raw_both_weeks_joined.drop_duplicates(subset=['Run_Date', 'CBIZ_Name'])\n",
    "dups_dropped_cbiz_gr = dups_dropped_cbiz.groupby(['CBIZ_Name']).count()['Run_Date'].reset_index().rename(columns={'Run_Date': 'count'})\n",
    "dups_dropped_cbiz_gr.loc[:, 'both_weeks'] = np.where(dups_dropped_cbiz_gr['count'] > 1, 'Yes', 'No')\n",
    "dups_dropped_cbiz_gr = dups_dropped_cbiz_gr.drop(columns=['count'])\n",
    "# join back to supply_raw_both_weeks_joined on 'CBIZ_Name' \n",
    "supply_raw_both_weeks_joined_2 = supply_raw_both_weeks_joined.merge(dups_dropped_cbiz_gr, on=['CBIZ_Name'], how='left')\n",
    "# if both_weeks is 'No' and 'Run_Date' == last_week then 'Capacity Filled' however, if both_weeks is 'No' and 'Run_Date' == today then 'New Capacity' make this as a new column 'Abstractor Changed'\n",
    "supply_raw_both_weeks_joined_2.loc[:, 'Abstractor Changed'] = np.where((supply_raw_both_weeks_joined_2['both_weeks'] == 'No') & (supply_raw_both_weeks_joined_2['Run_Date'] == latest_date_str), 'Capacity Filled', \n",
    "                                                                       np.where((supply_raw_both_weeks_joined_2['both_weeks'] == 'No') & (supply_raw_both_weeks_joined_2['Run_Date'] == today), 'New Capacity', ''))\n",
    "# rename current_skills to 'Product Skill Category'\n",
    "supply_raw_both_weeks_joined_2 = supply_raw_both_weeks_joined_2.rename(columns={'current_skills': 'Product Skill Category'})\n",
    "# replace any 0s with np.nan\n",
    "supply_raw_both_weeks_joined_2 = supply_raw_both_weeks_joined_2.replace(0, np.nan)\n",
    "supply_raw_both_weeks_joined_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supply_raw_both_weeks_joined_2[supply_raw_both_weeks_joined_2['Product Skill Category'] == 'PCI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat supply_last_week to the bottom of capbase_sel_capacity_exploded_drp\n",
    "demand_raw_both_weeks = pd.concat([ops_plan_sel_gr0, demand_last_week])\n",
    "demand_raw_both_weeks = demand_raw_both_weeks.replace('', np.nan)\n",
    "demand_raw_both_weeks.loc[:, 'Project Category'] = np.where(demand_raw_both_weeks['Project Category'] == 'Cancer', demand_raw_both_weeks['Project Category'] + ' - ' + demand_raw_both_weeks['Team Position'], demand_raw_both_weeks['Project Category'])\n",
    "# drop \"Team Position\"\n",
    "demand_raw_both_weeks = demand_raw_both_weeks.drop(columns=['Team Position'])\n",
    "print(len(demand_raw_both_weeks))\n",
    "demand_raw_both_weeks_gr = demand_raw_both_weeks.groupby(['Q-Centrix Team Name', 'Project Category', 'Requested Hours']).count()['Run_Date'].reset_index()\n",
    "demand_raw_both_weeks_gr = demand_raw_both_weeks_gr.rename(columns={'Run_Date': 'count'})\n",
    "demand_raw_both_weeks_gr.loc[:, 'Changed'] = np.where(demand_raw_both_weeks_gr['count'] > 1, 'No', 'Yes')\n",
    "# drop count column\n",
    "demand_raw_both_weeks_gr = demand_raw_both_weeks_gr.drop(columns=['count'])\n",
    "# join this back to the demand_raw_both_weeks dataframe\n",
    "demand_raw_both_weeks_joined = demand_raw_both_weeks.merge(demand_raw_both_weeks_gr, on=['Q-Centrix Team Name', 'Project Category', 'Requested Hours'], how='left')\n",
    "demand_raw_both_weeks_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distinct values in the 'Run_Date' and 'CBIZ_Name' columns\n",
    "dups_dropped_team_name = demand_raw_both_weeks_joined.drop_duplicates(subset=['Run_Date', 'Q-Centrix Team Name'])\n",
    "dups_dropped_team_name_gr = dups_dropped_team_name.groupby(['Q-Centrix Team Name']).count()['Run_Date'].reset_index().rename(columns={'Run_Date': 'count'})\n",
    "dups_dropped_team_name_gr.loc[:, 'both_weeks'] = np.where(dups_dropped_team_name_gr['count'] > 1, 'Yes', 'No')\n",
    "dups_dropped_team_name_gr = dups_dropped_team_name_gr.drop(columns=['count'])\n",
    "# join back to demand_raw_both_weeks_joined on 'CBIZ_Name' \n",
    "demand_raw_both_weeks_joined_2 = demand_raw_both_weeks_joined.merge(dups_dropped_team_name_gr, on=['Q-Centrix Team Name'], how='left')\n",
    "# if both_weeks is 'No' and 'Run_Date' == last_week then 'Capacity Filled' however, if both_weeks is 'No' and 'Run_Date' == today then 'New Capacity' make this as a new column 'Abstractor Changed'\n",
    "demand_raw_both_weeks_joined_2.loc[:, 'Demand Changed'] = np.where((demand_raw_both_weeks_joined_2['both_weeks'] == 'No') & (demand_raw_both_weeks_joined_2['Run_Date'] == latest_date_str), 'Demand Filled', \n",
    "                                                                       np.where((demand_raw_both_weeks_joined_2['both_weeks'] == 'No') & (demand_raw_both_weeks_joined_2['Run_Date'] == today), 'New Demand', ''))\n",
    "# replace any 0s with np.nan\n",
    "demand_raw_both_weeks_joined_2 = demand_raw_both_weeks_joined_2.replace(0, np.nan)\n",
    "demand_raw_both_weeks_joined_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{path_to_planning_teams_folder}Supply Demand Summary/supply_demand_analysis_{today}.xlsx\", engine='xlsxwriter')\n",
    "supply_demand_pr_index_merged_fil.to_excel(writer, sheet_name = 'Summary Core Lines')\n",
    "supply_demand_pr_index_merged_new_hires.to_excel(writer, sheet_name = 'Summary')\n",
    "supply_demand_pr_index_merged_new_hires_no_multi_last_week.to_excel(writer, sheet_name='Changes Since Last Week')\n",
    "supply_raw_both_weeks_joined_2.to_excel(writer, sheet_name='Capacity Changes', index=False)\n",
    "demand_raw_both_weeks_joined_2.to_excel(writer, sheet_name='Demand Changes', index=False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # After writing the data to Excel, open the workbook and set the column widths\n",
    "import openpyxl\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook(f\"{path_to_planning_teams_folder}Supply Demand Summary/supply_demand_analysis_{today}.xlsx\")\n",
    "\n",
    "# get all of the sheet names \n",
    "sheet_names = workbook.sheetnames\n",
    "for sheet_name in sheet_names:\n",
    "    # Select the sheet\n",
    "    sheet = workbook[sheet_name]\n",
    "    # print(sheet_name)\n",
    "    if sheet_name == 'Summary':\n",
    "        for column in sheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[1].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(cell.value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2) * 1.2\n",
    "            sheet.column_dimensions[column_letter].width = adjusted_width\n",
    "    else:\n",
    "        # Set the column widths\n",
    "        for column in sheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(cell.value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2) * 1.2\n",
    "            sheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# # Save the workbook\n",
    "workbook.save(f\"{path_to_planning_teams_folder}Supply Demand Summary/supply_demand_analysis_{today}.xlsx\")\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
