{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundant Capacity Optimization System\n",
    "## Professional Resource Management & Assignment Optimization\n",
    "\n",
    "### Project Overview\n",
    "This system optimizes the allocation of medical abstractors across different projects by identifying opportunities to redistribute experienced personnel to high-priority assignments while backfilling their previous positions with qualified trainees. The primary goal is to maximize the efficiency of resource utilization while ensuring all projects maintain appropriate skill coverage.\n",
    "\n",
    "### Business Context\n",
    "In healthcare data abstraction, experienced abstractors often possess multiple specialized skills, while newer team members (trainees) may have more limited skill sets. This creates an opportunity to optimize team deployment by:\n",
    "1. Identifying projects where experienced abstractors are working below their full skill capacity\n",
    "2. Relocating these abstractors to projects that require their advanced skill sets\n",
    "3. Backfilling their original positions with qualified trainees\n",
    "\n",
    "### Technical Implementation\n",
    "The system implements this optimization through several key components:\n",
    "\n",
    "1. **Resource Analysis**\n",
    "   - Evaluates current assignments and abstractor skill sets\n",
    "   - Identifies opportunities where experienced abstractors could be better utilized\n",
    "   - Calculates available capacity and required hours for each project\n",
    "\n",
    "2. **Scoring Algorithm**\n",
    "   - Ranks potential moves based on multiple factors:\n",
    "     - Full-time vs. part-time status\n",
    "     - Current workload\n",
    "     - Existing team assignments\n",
    "     - Skill match requirements\n",
    "     - Previous assignment history\n",
    "\n",
    "3. **Assignment Optimization**\n",
    "   - Generates optimal reassignment recommendations\n",
    "   - Ensures all projects maintain required skill coverage\n",
    "   - Validates that proposed changes meet business rules and constraints\n",
    "\n",
    "4. **Integration**\n",
    "   - Connects with Salesforce for real-time data\n",
    "   - Utilizes Excel for input/output of assignment plans\n",
    "   - Maintains tracking of historical movements and capacity changes\n",
    "\n",
    "### Technical Stack\n",
    "- Python (pandas, numpy)\n",
    "- Salesforce Integration (simple_salesforce)\n",
    "- Excel Integration (openpyxl)\n",
    "- Custom scoring and optimization algorithms\n",
    "\n",
    "### Output\n",
    "The system produces detailed reports showing:\n",
    "- Recommended resource movements\n",
    "- Backfill recommendations\n",
    "- Capacity impact analysis\n",
    "- Scoring breakdowns for all considered options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Code Summary\n",
    "\n",
    "## Core Components\n",
    "\n",
    "### Data Sources\n",
    "- Salesforce database (via simple_salesforce)\n",
    "- Excel files containing:\n",
    "  - Current capacity base\n",
    "  - Hours already shifted\n",
    "  - Daily assignment planning\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "1. `check_for_existing_assignment()`\n",
    "   - Validates if an abstractor is already assigned to a team\n",
    "   - Prevents single-resource teams from being disrupted\n",
    "   - Returns scoring modifications based on assignment status\n",
    "\n",
    "2. `score_row()`\n",
    "   - Implements the scoring algorithm for potential moves\n",
    "   - Considers factors such as:\n",
    "     - Full/Part time status (+0/+4 points)\n",
    "     - Hours match proximity (+2 points if within 0.5 hours)\n",
    "     - Existing team assignment (+10/-10 points)\n",
    "     - Previous shifts (-10 points if already being shifted)\n",
    "\n",
    "### Main Process Flow\n",
    "\n",
    "1. **Initial Setup**\n",
    "   - Loads configuration and current assignments\n",
    "   - Filters for relevant categories and skills\n",
    "   - Establishes scoring criteria\n",
    "\n",
    "2. **Capacity Analysis**\n",
    "   - Identifies abstractors with potential for movement\n",
    "   - Calculates available hours and needed coverage\n",
    "   - Filters based on minimum working hours (2+ hours in 4 or 12 week periods)\n",
    "\n",
    "3. **Optimization Loop**\n",
    "   - For each target category:\n",
    "     - Scores potential moves\n",
    "     - Identifies optimal reassignments\n",
    "     - Calculates backfill requirements\n",
    "     - Updates capacity tracking\n",
    "\n",
    "4. **Output Generation**\n",
    "   - Creates Excel workbook with multiple sheets:\n",
    "     - Distribution recommendations\n",
    "     - Distribution options\n",
    "     - Backfill options\n",
    "   - Maintains tracking file of processed movements\n",
    "\n",
    "### Key Features\n",
    "- Prevents disruption of critical assignments\n",
    "- Maintains skill coverage requirements\n",
    "- Tracks and prevents double-booking of resources\n",
    "- Provides multiple options for each recommended move\n",
    "- Generates comprehensive documentation of decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from simple_salesforce import Salesforce\n",
    "# Import the module under a specific name\n",
    "import importlib\n",
    "import sf_queries_class\n",
    "importlib.reload(sf_queries_class)\n",
    "from sf_queries_class import SfQueries\n",
    "import my_sf_secrets\n",
    "import helper_fx\n",
    "import capacity_portion\n",
    "importlib.reload(capacity_portion)\n",
    "import create_capbase\n",
    "importlib.reload(create_capbase)\n",
    "my_sf_username, my_sf_password, my_sf_security_token = my_sf_secrets.get_my_sf_secrets()\n",
    "queries = SfQueries(\n",
    "    username=my_sf_username,\n",
    "    password=my_sf_password,\n",
    "    security_token=my_sf_security_token\n",
    ")\n",
    "\n",
    "# get the username from the system\n",
    "username = os.getlogin()\n",
    "print(f'{filename}')\n",
    "from reportforce import Reportforce\n",
    "rf = Reportforce(session_id=queries.sf.session_id, instance_url=queries.sf.sf_instance)\n",
    "\n",
    "capbase = pd.read_excel(filename).fillna({'current_skills': \"\"})\n",
    "assignment_hours_already_shifted = pd.read_excel('hours_already_shifted.xlsx')\n",
    "todays_needs = pd.read_excel(f\"Daily Tools/Assignment_Planning_{today}.xlsx\", sheet_name='Summary')\n",
    "todays_needs_fil = todays_needs[todays_needs['Suggested Resource'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_with_capacity_to_shift = ('cat1', 'cat2')\n",
    "pci_sts_acs = capacity_portion.category_capacity(list(cats_with_capacity_to_shift), capbase, capacity_filter=False)\n",
    "sorted(pci_sts_acs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_existing_assignment(CBIZ_Name, request_names, risk_mitigation_resource):\n",
    "    team_ids = []\n",
    "    for request_name in request_names:\n",
    "        team_id = queries.get_sr_from_request_name(request_name)['ID'].values[0]\n",
    "        team_ids.append(team_id)\n",
    "    abstractor_id = queries.get_contact_id_from_CBIZ_Name(CBIZ_Name)\n",
    "    team_members = queries.get_abstractor_assignments(team_id=team_ids[0])\n",
    "    team_members_abs = team_members[(team_members['Team_Position__c'] == 'Abstractor') &\n",
    "                                    (team_members['Resource__r.Name'] != risk_mitigation_resource)]\n",
    "    if (risk_mitigation_resource is not None) and (risk_mitigation_resource is not np.nan):\n",
    "        if (abstractor_id == queries.get_contact_id_from_CBIZ_Name(risk_mitigation_resource)):\n",
    "            return -10\n",
    "    if (len(team_members_abs) <= 1) & (abstractor_id in list(team_members_abs['Id'])):\n",
    "        return -10\n",
    "    elif abstractor_id in list(team_members_abs['Id']):\n",
    "        return 10\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_row(row, cap_col_name, hours_needed, request_name, risk_mitigation_resource, already_shifting=None):\n",
    "    score = 0\n",
    "    \n",
    "    # Score based on Full Time Status\n",
    "    if row['Full Time Status'] == 'PT':\n",
    "        score += 4\n",
    "    elif row['Full Time Status'] == 'FT':\n",
    "        score += 0\n",
    "    \n",
    "    # Score based on proximity to hours_needed\n",
    "    if abs(row[cap_col_name] - hours_needed) <= 0.5:\n",
    "        score += 2\n",
    "    \n",
    "    # Add to Score if already on team\n",
    "    score += check_for_existing_assignment(row['CBIZ_Name'], request_name, risk_mitigation_resource[0])\n",
    "\n",
    "    # if the abstractor is already being shifted, reduce the score by 1\n",
    "    if already_shifting is not None:\n",
    "        if (row['CBIZ_Name'].split(' - ')[0] in already_shifting) or (row['CBIZ_Name'] in already_shifting):\n",
    "            # print(score)\n",
    "            score -= 10\n",
    "            # print(f\"abstractor: {row['CBIZ_Name']} is already shifting {score}\")\n",
    "    \n",
    "    # Score based on row position\n",
    "    # score += (1 / (index + 1))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_needs_fil['Project Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will check if any of them are already on the project that has a staffing request, \n",
    "# and if they are the only one, if not, then give them the highest ranking\n",
    "assignment_hours_already_shifted = pd.read_excel('hours_already_shifted.xlsx')\n",
    "cats_with_capacity_to_shift = ('cat1', 'cat2')\n",
    "pci_sts_acs = capacity_portion.category_capacity(list(cats_with_capacity_to_shift), capbase, capacity_filter=False)\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter(f\"Daily Tools/Redundant_Capacity_Planning_{today}.xlsx\", engine='xlsxwriter')\n",
    "requests_to_exclude = ['specific requests']\n",
    "pci_abstractors_to_exclude = ['specific abstractors']\n",
    "\n",
    "target_categories = todays_needs_fil['Project Category'].unique()\n",
    "todays_needs_fil = todays_needs_fil[~todays_needs_fil['Request Name'].isin(requests_to_exclude)]\n",
    "# group by team name and sum the Hours Requested column\n",
    "# and aggregate 'Request Name' and 'Risk Mitigation Resource: Full Name' into lists\n",
    "todays_needs_fil_gr = todays_needs_fil.groupby(['Team Name', 'Project Category']) \\\n",
    "    .agg({'Request Name': list, 'Risk Mitigation Resource: Full Name': list, 'Requested Hours': 'sum'}) \\\n",
    "    .reset_index()\n",
    "\n",
    "# Concatenate the lists of 'Request Name' and 'Risk Mitigation Resource: Full Name' \n",
    "# into a single string for each group\n",
    "todays_needs_fil_gr['Combined Names'] = todays_needs_fil_gr.apply(\n",
    "    lambda row: ', '.join(f\"{req} - {name}\" if name else req for req, name in zip(\n",
    "        row['Request Name'], row['Risk Mitigation Resource: Full Name'])), axis=1\n",
    ")\n",
    "\n",
    "for target_category in ['TC1', 'TC2']:\n",
    "    redundant_capacity_df, final_redundant_capacity_df, all_redundant_options_df, all_backfill_options_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    if target_category == 'Specific category 1':\n",
    "        target_category_skills = 'SC1'\n",
    "    elif 'Specific category 2' in target_category:\n",
    "        target_category_skills = 'Specific category 2'\n",
    "    else:\n",
    "        target_category_skills = target_category\n",
    "    \n",
    "\n",
    "    pci_sts_acs_sel = pci_sts_acs[(~pci_sts_acs.CBIZ_Name.isin(pci_abstractors_to_exclude)) &\n",
    "                            (pci_sts_acs['current_skills'].str.contains(target_category_skills))].copy()\n",
    "    # print(pci_sts_acs_sel)\n",
    "    if len(pci_sts_acs_sel) > 0: \n",
    "        target_cat_abstractor_assignments = queries.get_all_assignments(pci_sts_acs_sel, 'CBIZ_Name')\n",
    "        target_cat_abstractor_assignments_real = target_cat_abstractor_assignments[\n",
    "            ((target_cat_abstractor_assignments['Project_Category__c'].str.contains(cats_with_capacity_to_shift[0])) | \n",
    "             (target_cat_abstractor_assignments['Project_Category__c'].str.contains(cats_with_capacity_to_shift[1]))) & \n",
    "                                    ((target_cat_abstractor_assignments['Wrkd_12__c'] >= 2) |\n",
    "                                    (target_cat_abstractor_assignments['Wrkd_4__c'] >= 2)) & \n",
    "                                    (~target_cat_abstractor_assignments['Team_Position__c'].isin(['QAR', 'Temporary Resource', 'Backup'])) &\n",
    "                                     (target_cat_abstractor_assignments['Project_Not_Eligible_for_Trainee__c'] == False) &\n",
    "                                     (~target_cat_abstractor_assignments['Id'].isin(assignment_hours_already_shifted['id'].values))\n",
    "                                    ].copy()\n",
    "        target_cat_abstractor_assignments_real.loc[:, 'CBIZ_Name'] = target_cat_abstractor_assignments_real['Resource__r.Name'] + ' - ' + \\\n",
    "            target_cat_abstractor_assignments_real['Resource__r.External_Employee_ID__c'].astype(int).astype(str)\n",
    "\n",
    "        target_cat_abstractor_assignments_real_merged = target_cat_abstractor_assignments_real.rename(\n",
    "            columns={'Resource__r.Full_Time_Status__c': 'Full Time Status'}\n",
    "            ).sort_values(by=['Full Time Status', 'Wrkd_12__c'], ascending=[False, False])\n",
    "\n",
    "        hours_needed_in_target_category =  sum(todays_needs_fil_gr.loc[\n",
    "            (todays_needs_fil_gr['Project Category'] == target_category), 'Requested Hours'])\n",
    "        target_category_requests = todays_needs_fil_gr.loc[\n",
    "            (todays_needs_fil_gr['Project Category'] == target_category), ['Team Name', 'Requested Hours', \n",
    "                                                                             'Request Name', 'Risk Mitigation Resource: Full Name']]\n",
    "        # print(hours_needed_in_target_category)\n",
    "        if len(target_cat_abstractor_assignments_real_merged) > 0:\n",
    "            iteration = 0\n",
    "            for row_requests in target_category_requests.iterrows():\n",
    "                # print(row_requests)\n",
    "                hours_needed = row_requests[1]['Requested Hours']\n",
    "                # print(hours_needed)\n",
    "                # print(f\"request name: {row_requests[1]['Request Name']}, name: {row_requests[1]['Risk Mitigation Resource: Full Name']}\")\n",
    "                target_cat_abstractor_assignments_real_merged.reset_index(drop=True, inplace=True)\n",
    "                target_cat_abstractor_assignments_real_merged['Score'] = target_cat_abstractor_assignments_real_merged.apply(\n",
    "                    lambda row: score_row(row, 'Wrkd_12__c', hours_needed, row_requests[1]['Request Name'], \n",
    "                                          row_requests[1]['Risk Mitigation Resource: Full Name'], \n",
    "                                          already_shifting=assignment_hours_already_shifted['abstractor_name'].values), axis=1)\n",
    "\n",
    "                # Sort the dataframe by score in descending order\n",
    "                target_cat_abstractor_assignments_real_merged_sorted = \\\n",
    "                    target_cat_abstractor_assignments_real_merged.sort_values('Score', ascending=False)\n",
    "                \n",
    "                    \n",
    "                # get the first row of the sorted dataframe and determine if the 'Wrkd_12__c' \n",
    "                # is greater than or equal to the hours needed\n",
    "                \n",
    "                while (hours_needed > 0) and (iteration < len(target_cat_abstractor_assignments_real_merged_sorted)):\n",
    "                    # print(f'hours needed: {hours_needed}')\n",
    "                    first_row = target_cat_abstractor_assignments_real_merged_sorted.iloc[[iteration]].copy()\n",
    "                    # print(f'first_row: {first_row.columns}')\n",
    "                    first_row.loc[:, 'Wrkd_12__c'] = np.floor(first_row['Wrkd_12__c'])\n",
    "                    first_row.loc[:, 'Wrkd_4__c'] = np.floor(first_row['Wrkd_4__c'])\n",
    "                    hours_available = first_row['Wrkd_12__c'].iloc[0]\n",
    "                    first_row.loc[:, 'New Project Name'] = row_requests[1]['Team Name']\n",
    "                    first_row.loc[:, 'Hours Requested'] = row_requests[1]['Requested Hours']\n",
    "                    first_row = first_row.rename(columns={'Name': 'Old Project Name',\n",
    "                                                          'Project_Category__c': 'Backfill Project Category'})\n",
    "                    first_row.loc[:, 'New Assignment Hours'] = min(hours_available, hours_needed)\n",
    "                    first_row_sel = first_row[['CBIZ_Name', 'Wrkd_4__c', 'Wrkd_12__c', 'Hours Requested', 'New Assignment Hours',\n",
    "                                                'New Project Name', 'Backfill Project Category', 'Old Project Name']].copy()\n",
    "                    # print(first_row_sel)\n",
    "                    try:\n",
    "                        redundant_capacity_df = pd.concat([redundant_capacity_df, first_row_sel])\n",
    "                    except:\n",
    "                        redundant_capacity_df = first_row_sel\n",
    "                    # add this assignment to the dataframe of assignments that have already been shifted.\n",
    "                    # get the data in the correct format\n",
    "                    first_row_to_already_shifted = first_row[['Id', 'CBIZ_Name', \n",
    "                                            'Old Project Name', 'New Project Name']]\\\n",
    "                                            .rename(columns={\n",
    "                                                'Id': 'id',\n",
    "                                                'CBIZ_Name': 'abstractor_name',\n",
    "                                                'Old Project Name': 'old_project',\n",
    "                                                'New Project Name': 'New Project'\n",
    "                                            }).copy()\n",
    "                    first_row_to_already_shifted.loc[:, 'id'] = first_row_to_already_shifted['id'].str.strip()\n",
    "                    # if the abstractor can either cover the assignment or partially cover the assignment, \n",
    "                    # then subtract from hours needed and iterate to the next abstractor\n",
    "                    if hours_available <= hours_needed:\n",
    "                        # add this assignment to the dataframe of assignments that have already been shifted.\n",
    "                        assignment_hours_already_shifted = pd.concat([assignment_hours_already_shifted, first_row_to_already_shifted])\n",
    "                        # reduce the 'Wrkd_12__c' to 0\n",
    "                        target_cat_abstractor_assignments_real_merged_sorted.iloc[\n",
    "                            iteration, list(target_cat_abstractor_assignments_real_merged_sorted.columns).index('Wrkd_12__c')] = 0\n",
    "                        iteration += 1\n",
    "                    # however, if the abstractor can cover the assignment and then have extra hours left over, \n",
    "                    # they can move on to the next request without iterating\n",
    "                    elif hours_available >= (hours_needed + 2):\n",
    "                        target_cat_abstractor_assignments_real_merged_sorted.iloc[\n",
    "                            iteration, \n",
    "                            list(target_cat_abstractor_assignments_real_merged_sorted.columns).index('Wrkd_12__c')] = \\\n",
    "                            first_row['Wrkd_12__c'].iloc[0] - hours_needed\n",
    "\n",
    "                        hours_available -= hours_needed\n",
    "                    # otherwise just move on to the next abstractor\n",
    "                    else:\n",
    "                        # add this assignment to the dataframe of assignments that have already been shifted.\n",
    "                        assignment_hours_already_shifted = pd.concat([assignment_hours_already_shifted, first_row_to_already_shifted])\n",
    "                        # reduce the 'Wrkd_12__c' to 0\n",
    "                        target_cat_abstractor_assignments_real_merged_sorted.iloc[\n",
    "                            iteration, list(target_cat_abstractor_assignments_real_merged_sorted.columns).index('Wrkd_12__c')] = 0\n",
    "                        iteration += 1\n",
    "                    # we always need to decrement the hours needed by the hours available\n",
    "                    hours_needed -= first_row['Wrkd_12__c'].iloc[0]\n",
    "                # done with the while loop, so lets get the scores for the abstractors that were used for this request\n",
    "                redundant_options = target_cat_abstractor_assignments_real_merged_sorted[['Id', 'CBIZ_Name', 'Wrkd_4__c', \n",
    "                                                                                            'Wrkd_12__c', 'Full Time Status',\n",
    "                                                                                            'Project_Category__c', 'Score']].copy()\n",
    "                redundant_options.loc[:, 'Request Name'] = row_requests[1]['Request Name'][0]\n",
    "                redundant_options.loc[:, 'New Team Name'] = row_requests[1]['Team Name']\n",
    "                try:\n",
    "                    all_redundant_options_df = pd.concat([all_redundant_options_df, redundant_options.head(10)])\n",
    "                except:\n",
    "                    all_redundant_options_df = redundant_options.head(10)\n",
    "            \n",
    "\n",
    "\n",
    "            # Now that we have the dataframe of the assignments that need to be shifted, \n",
    "            # we need to find the abstractors with capacity that can backfill those assignments\n",
    "            \n",
    "            if len(redundant_capacity_df) > 0:\n",
    "                \n",
    "                for redundant_cap_row in redundant_capacity_df.iterrows():\n",
    "                    # print(redundant_cap_row[1])\n",
    "                    replacement_hours_needed = redundant_cap_row[1]['New Assignment Hours']\n",
    "                    abstractors_with_capacity_fil = pci_sts_acs[\n",
    "                        (pci_sts_acs['Capticket Hours'] > 0.5) & \n",
    "                        (pci_sts_acs['current_skills'].str.contains(redundant_cap_row[1]['Backfill Project Category']))].copy()\n",
    "                    abstractors_with_capacity_fil = abstractors_with_capacity_fil.sort_values(by = ['Resource_Start_Date', 'Capticket Hours'], ascending=[True, False])\n",
    "                    abstractors_with_capacity_fil.reset_index(drop=True, inplace=True)\n",
    "                    abstractors_with_capacity_fil['Score'] = abstractors_with_capacity_fil.apply(\n",
    "                        lambda redundant_cap_row: score_row(redundant_cap_row, 'Capticket Hours', replacement_hours_needed, row_requests[1]['Request Name'], \n",
    "                                          row_requests[1]['Risk Mitigation Resource: Full Name']), axis=1)\n",
    "                    \n",
    "                    abstractors_with_capacity_fil = abstractors_with_capacity_fil.sort_values('Score', ascending=False)\n",
    "                                            \n",
    "                    redundant_cap_row[1]['Backfill Abstractor'] = ''\n",
    "                    iteration_capacity = 0\n",
    "                    while (replacement_hours_needed > 0) & (iteration_capacity < 10):\n",
    "                        # print(f'replacement hours needed: {replacement_hours_needed}')\n",
    "                        first_row_capacity = abstractors_with_capacity_fil.iloc[[iteration_capacity]]\n",
    "                        first_row_capacity.loc[:, 'Capticket Hours'] = np.floor(first_row_capacity['Capticket Hours'])\n",
    "                        if first_row_capacity['Capticket Hours'].iloc[0] <= replacement_hours_needed:\n",
    "                            if len(redundant_cap_row[1]['Backfill Abstractor']) == 0:\n",
    "                                redundant_cap_row[1]['Backfill Abstractor'] = first_row_capacity['CBIZ_Name'].iloc[0] + f\"({first_row_capacity['Capticket Hours'].iloc[0]})\"\n",
    "                            else:\n",
    "                                redundant_cap_row[1]['Backfill Abstractor'] = redundant_cap_row[1]['Backfill Abstractor'] + ', ' +\\\n",
    "                                    first_row_capacity['CBIZ_Name'].iloc[0] + f\"({first_row_capacity['Capticket Hours'].iloc[0]})\"\n",
    "                            # abstractors_with_capacity_fil.iloc[\n",
    "                            #     0, list(abstractors_with_capacity_fil.columns).index('Capticket Hours')] = 0\n",
    "                            # reduce the hours available in the pci_sts_acs dataframe for this abstractor\n",
    "                            pci_sts_acs.loc[pci_sts_acs['CBIZ_Name'] == first_row_capacity['CBIZ_Name'].iloc[0], 'Capticket Hours'] = 0\n",
    "                            iteration_capacity += 1\n",
    "                        elif first_row_capacity['Capticket Hours'].iloc[0] >= (replacement_hours_needed + 2):\n",
    "                            if len(redundant_cap_row[1]['Backfill Abstractor']) == 0:\n",
    "                                redundant_cap_row[1]['Backfill Abstractor'] = first_row_capacity['CBIZ_Name'].iloc[0]\n",
    "                            else:\n",
    "                                redundant_cap_row[1]['Backfill Abstractor'] = redundant_cap_row[1]['Backfill Abstractor'] + ', ' +\\\n",
    "                                    first_row_capacity['CBIZ_Name'].iloc[0]\n",
    "                            abstractors_with_capacity_fil.iloc[\n",
    "                                0, list(abstractors_with_capacity_fil.columns).index('Capticket Hours')] = \\\n",
    "                                    first_row_capacity['Capticket Hours'].iloc[0] - replacement_hours_needed\n",
    "                            # reduce the hours available in the pci_sts_acs dataframe for this abstractor\n",
    "                            pci_sts_acs.loc[pci_sts_acs['CBIZ_Name'] == first_row_capacity['CBIZ_Name'].iloc[0], 'Capticket Hours'] -= replacement_hours_needed\n",
    "                        else:\n",
    "                            if len(redundant_cap_row[1]['Backfill Abstractor']) == 0:\n",
    "                                redundant_cap_row[1]['Backfill Abstractor'] = first_row_capacity['CBIZ_Name'].iloc[0]\n",
    "                            else:\n",
    "                                redundant_cap_row[1]['Backfill Abstractor'] = redundant_cap_row[1]['Backfill Abstractor'] + ', ' +\\\n",
    "                                    first_row_capacity['CBIZ_Name'].iloc[0]\n",
    "                            # reduce the hours available in the pci_sts_acs dataframe for this abstractor\n",
    "                            # abstractors_with_capacity_fil.iloc[\n",
    "                            #     0, list(abstractors_with_capacity_fil.columns).index('Capticket Hours')] = 0\n",
    "                            pci_sts_acs.loc[pci_sts_acs['CBIZ_Name'] == first_row_capacity['CBIZ_Name'].iloc[0], 'Capticket Hours'] = 0\n",
    "                            iteration_capacity += 1\n",
    "                        replacement_hours_needed -= first_row_capacity['Capticket Hours'].iloc[0]\n",
    "                        # print(redundant_cap_row) #[1]['Backfill Abstractor']\n",
    "                        try:\n",
    "                            final_redundant_capacity_df = pd.concat([final_redundant_capacity_df, redundant_cap_row[1].to_frame().T])\n",
    "                        except:\n",
    "                            final_redundant_capacity_df = redundant_cap_row[1].to_frame().T\n",
    "                    # done with the while loop, so lets get the scores for the abstractors that were used for this request\n",
    "                    backfill_options = abstractors_with_capacity_fil[['CBIZ_Name', 'Capticket Hours', 'Resource_Start_Date', 'Full Time Status',\n",
    "                                                                      'Paid Onboarding Program', 'Score', 'current_skills', 'Capacity_Planned']].copy()\n",
    "                    backfill_options.loc[:, 'Backfill Project'] = redundant_cap_row[1]['Old Project Name']\n",
    "                    backfill_options.loc[:, 'Backfill Project Hours'] = redundant_cap_row[1]['New Assignment Hours']\n",
    "                    try:\n",
    "                        all_backfill_options_df = pd.concat([all_backfill_options_df, backfill_options.head(10)])\n",
    "                    except:\n",
    "                        all_backfill_options_df = backfill_options.head(10)\n",
    "            else:\n",
    "                print(f'there were no abstractors available for redundant capacity')\n",
    "                \n",
    "        else:\n",
    "            print(f'After filtering, no assignments in {target_category} met the criteria')\n",
    "\n",
    "    else:\n",
    "        print(f'No abstractors in Tr_cats also have the skill in {target_category}')\n",
    "    if len(final_redundant_capacity_df) > 0:\n",
    "        final_redundant_capacity_df.to_excel(writer, sheet_name = f'{target_category}_distr', index=False)\n",
    "        all_redundant_options_df.to_excel(writer, sheet_name = f'{target_category}_dis_op', index=False)\n",
    "        all_backfill_options_df.to_excel(writer, sheet_name = f'{target_category}_BF_op', index=False)\n",
    "    # if we are all out of capacity then break the loop\n",
    "    if len(pci_sts_acs[pci_sts_acs['Capticket Hours'] > 0.5]) == 0:\n",
    "        print(f'There are no abstractors with capacity left, and we were on {target_category}')\n",
    "        break\n",
    "writer.close()\n",
    "\n",
    "create_capbase.adjust_workbook_column_widths(f\"Daily Tools/Redundant_Capacity_Planning_{today}.xlsx\")\n",
    "assignment_hours_already_shifted.to_csv(f'Temp_assignments_already_shifted.csv', index=False)\n",
    "final_redundant_capacity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstractors_with_capacity_fil"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
